{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fbfd56",
   "metadata": {},
   "source": [
    "# ASA x LFM2.5-1.2B-Instruct (Liquid Official Prompt)\n",
    "**Maxime Labonne Feedback: Adopting Liquid standard Tool Use format**\n",
    "\n",
    "This notebook replicates the ASA pipeline using the **official Liquid Tool Use prompt format**\n",
    "(`List of tools: {json}`) instead of the Qwen-style system prompt used in the original experiment.\n",
    "\n",
    "Reference: [Liquid Tool Use Docs](https://docs.liquid.ai/docs/key-concepts/tool-use)\n",
    "\n",
    "Changes from original:\n",
    "- System prompt: `List of tools: {json}` (Liquid official) instead of `You are a helpful assistant...`\n",
    "- No explicit trigger token instructions (LFM2.5 knows `<|tool_call_start|>` natively)\n",
    "- Compact JSON (no indent)\n",
    "- Also tests `apply_chat_template(tools=...)` via HuggingFace API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aed1bc",
   "metadata": {},
   "source": [
    "## 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b888852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "VRAM: 15.6 GB\n",
      "Setup done.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "for p in [\"transformers>=4.40.0\",\"accelerate>=0.25.0\",\"scikit-learn>=1.3.0\",\n",
    "           \"datasets\",\"tqdm\",\"matplotlib\",\"seaborn\"]:\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",p])\n",
    "\n",
    "import os, json, re, pickle, warnings, gc, ast\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib; matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    try: print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
    "    except AttributeError: pass\n",
    "\n",
    "MODEL_ID = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
    "DOMAINS  = [\"math\",\"code\",\"search\",\"translation\"]\n",
    "SEED = 42; np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "OUT   = Path(\"outputs_liquid\"); OUT.mkdir(exist_ok=True)\n",
    "CKPT  = OUT/\"ckpt\"; CKPT.mkdir(exist_ok=True)\n",
    "\n",
    "TOOL_S = \"<|tool_call_start|>\"\n",
    "TOOL_E = \"<|tool_call_end|>\"\n",
    "\n",
    "def save_ckpt(tag, obj):\n",
    "    p=CKPT/f\"{tag}.pkl\"\n",
    "    with open(p,\"wb\") as f: pickle.dump(obj,f)\n",
    "    print(f\"  save {tag} ({p.stat().st_size//1024}KB)\")\n",
    "def load_ckpt(tag):\n",
    "    p=CKPT/f\"{tag}.pkl\"\n",
    "    if p.exists():\n",
    "        with open(p,\"rb\") as f: o=pickle.load(f)\n",
    "        print(f\"  load {tag} (cached)\"); return o\n",
    "    return None\n",
    "print(\"Setup done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf3631",
   "metadata": {},
   "source": [
    "## 2 - Data Pipeline\n",
    "Download **Alpaca** and apply domain filtering + tool-necessity heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96989bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Alpaca dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f54836418840448c021191fa208a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7484f90ee14e978d1c13e53f5e1e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-a09b74b3ef9c3b(…):   0%|          | 0.00/24.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b6b88737ad476f9d13fa9a7f530fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Alpaca: 52002 samples\n",
      "\n",
      "Filtered counts:\n",
      "  math        : tool=1537  non-tool=4561\n",
      "  code        : tool=2153  non-tool=2811\n",
      "  search      : tool=1174  non-tool= 173\n",
      "  translation : tool= 236  non-tool=  31\n",
      "\n",
      "Split sizes:\n",
      "  cal  : 320 (160 tool / 160 non-tool)\n",
      "  train: 320 (160 tool / 160 non-tool)\n",
      "  valid: 320 (160 tool / 160 non-tool)\n",
      "  test : 640 (320 tool / 320 non-tool)\n",
      "Total: 1600 unique samples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Downloading Alpaca dataset...\")\n",
    "alpaca = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n",
    "print(f\"  Alpaca: {len(alpaca)} samples\")\n",
    "\n",
    "# Domain classification + tool-necessity labeling\n",
    "_MATH_KW = re.compile(r'(calcul|comput|solve|equation|formula|\\bsum\\b|product|divid|multiply|percent|fraction|area|volume|circumferen|triangle|circle|rectangle|convert.*to|\\bhow much\\b|\\bhow many\\b|average|median|ratio|proportion|interest|mortgage|speed|distance|temperature|celsius|fahrenheit|kilometer|gallon|\\bcos\\b|\\bsin\\b|\\btan\\b|factorial|logarithm|square root|hypotenuse|diagonal|perimeter|probability)', re.I)\n",
    "_CODE_KW = re.compile(r'(python|javascript|java\\b|\\bc\\+\\+|\\bhtml\\b|\\bcss\\b|\\bsql\\b|function|script|algorithm|debug|compil|execut|output|variable|\\bloop\\b|\\barray\\b|\\bclass\\b|\\bimport\\b|\\bprint\\b|\\bsort\\b|\\bcode\\b|program|def\\s|for\\s.*in\\s|while\\s|if\\s.*else)', re.I)\n",
    "_SRCH_KW = re.compile(r'(who (is|was|are|were)|what (year|country|city)|when (did|was)|where (is|was)|capital of|population of|president of|founded|invented|discovered|located|\\bfind\\b.*about|search for|look up|latest|current|recent|today)', re.I)\n",
    "_TRNS_KW = re.compile(r'(translat|\\bin spanish\\b|\\bin french\\b|\\bin german\\b|\\bin chinese\\b|\\bin japanese\\b|\\bin korean\\b|\\bin arabic\\b|\\bin italian\\b|\\bin portuguese\\b|\\bin russian\\b|how do you say|\\bà\\b|\\büber\\b|en fran[cç]ais)', re.I)\n",
    "_CONCEPT = re.compile(r'(explain|describe|what is the (concept|difference|significance|meaning|history|importance)|why (is|are|do|does)|how does.*work|compare and contrast|pros and cons|advantages|definition of)', re.I)\n",
    "_HAS_NUM = re.compile(r'\\d+\\.?\\d*')\n",
    "\n",
    "def classify(inst, inp=\"\"):\n",
    "    t = (inst+\" \"+inp).strip()\n",
    "    tl = t.lower()\n",
    "    scores = {\"math\": len(_MATH_KW.findall(tl)),\n",
    "              \"code\": len(_CODE_KW.findall(tl)),\n",
    "              \"search\": len(_SRCH_KW.findall(tl)),\n",
    "              \"translation\": len(_TRNS_KW.findall(tl))}\n",
    "    dom = max(scores, key=scores.get)\n",
    "    if scores[dom] == 0: return None, None\n",
    "    is_concept = bool(_CONCEPT.search(tl))\n",
    "    if dom == \"math\":\n",
    "        has_num = bool(_HAS_NUM.search(t))\n",
    "        has_verb = bool(re.search(r'(calcul|comput|solve|convert|find the|determine|how much|how many)', tl))\n",
    "        label = 1 if (has_num and has_verb and not is_concept) else 0\n",
    "    elif dom == \"code\":\n",
    "        has_action = bool(re.search(r'(write|create|implement|build|generate|debug|fix|run|execute|test|develop)', tl))\n",
    "        label = 1 if (has_action and not is_concept) else 0\n",
    "    elif dom == \"search\":\n",
    "        label = 0 if is_concept else 1\n",
    "    elif dom == \"translation\":\n",
    "        has_target = bool(re.search(r'(translat.*to|in (spanish|french|german|chinese|japanese|korean|arabic|italian|portuguese|russian))', tl))\n",
    "        label = 1 if (has_target and not is_concept) else 0\n",
    "    else:\n",
    "        return None, None\n",
    "    return dom, label\n",
    "\n",
    "filtered = {d: {0: [], 1: []} for d in DOMAINS}\n",
    "for row in alpaca:\n",
    "    inst = row[\"instruction\"]\n",
    "    inp  = row.get(\"input\", \"\")\n",
    "    dom, label = classify(inst, inp)\n",
    "    if dom is None: continue\n",
    "    text = inst + (\"\\n\" + inp if inp else \"\")\n",
    "    filtered[dom][label].append(text)\n",
    "\n",
    "print(\"\\nFiltered counts:\")\n",
    "for d in DOMAINS:\n",
    "    print(f\"  {d:12s}: tool={len(filtered[d][1]):4d}  non-tool={len(filtered[d][0]):4d}\")\n",
    "\n",
    "PER_DOM = {\"cal\": (40,40), \"train\": (40,40), \"valid\": (40,40), \"test\": (80,80)}\n",
    "TOTAL_NEEDED = sum(t+n for t,n in PER_DOM.values())\n",
    "\n",
    "all_data = {}\n",
    "sample_id = 0\n",
    "for split, (nt, nn) in PER_DOM.items():\n",
    "    all_data[split] = []\n",
    "\n",
    "for d in DOMAINS:\n",
    "    for label in [0, 1]:\n",
    "        random_pool = filtered[d][label].copy()\n",
    "        np.random.shuffle(random_pool)\n",
    "        idx = 0\n",
    "        for split, (nt, nn) in PER_DOM.items():\n",
    "            need = nt if label == 1 else nn\n",
    "            for _ in range(need):\n",
    "                if idx < len(random_pool):\n",
    "                    text = random_pool[idx]; idx += 1\n",
    "                else:\n",
    "                    text = f\"[placeholder {d} {'tool' if label else 'nontool'} {sample_id}]\"\n",
    "                all_data[split].append({\n",
    "                    \"id\": f\"{d}_{split}_{label}_{sample_id}\",\n",
    "                    \"instruction\": text, \"domain\": d, \"label\": label\n",
    "                })\n",
    "                sample_id += 1\n",
    "\n",
    "for split in all_data:\n",
    "    np.random.shuffle(all_data[split])\n",
    "\n",
    "print(\"\\nSplit sizes:\")\n",
    "for split, samples in all_data.items():\n",
    "    t = sum(1 for s in samples if s[\"label\"]==1)\n",
    "    print(f\"  {split:5s}: {len(samples)} ({t} tool / {len(samples)-t} non-tool)\")\n",
    "\n",
    "all_ids = set()\n",
    "for split in all_data:\n",
    "    for s in all_data[split]:\n",
    "        assert s[\"id\"] not in all_ids; all_ids.add(s[\"id\"])\n",
    "print(f\"Total: {len(all_ids)} unique samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052db7ef",
   "metadata": {},
   "source": [
    "## 3 - Tools & System Prompt (Liquid Official Format)\n",
    "**Key change**: Uses `List of tools: {json}` format per\n",
    "[Liquid Tool Use docs](https://docs.liquid.ai/docs/key-concepts/tool-use).\n",
    "\n",
    "Original Qwen-style prompt had explicit trigger instructions that may cause over-triggering.\n",
    "The new Liquid official format is minimal: just the tool definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffe6117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD system prompt: 1670 chars\n",
      "NEW system prompt: 1032 chars\n",
      "Reduction: 638 chars (38%)\n",
      "\n",
      "NEW prompt preview:\n",
      "List of tools: [{\"name\": \"calculator\", \"description\": \"Evaluate a mathematical expression and return the numeric result.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expression\": {\"type\": \"strin...\n",
      "\n",
      "Liquid official format: 4 tools\n"
     ]
    }
   ],
   "source": [
    "TOOLS = [\n",
    "  {\"name\":\"calculator\",\"description\":\"Evaluate a mathematical expression and return the numeric result.\",\n",
    "   \"parameters\":{\"type\":\"object\",\"properties\":{\"expression\":{\"type\":\"string\",\"description\":\"Math expression\"}},\"required\":[\"expression\"]}},\n",
    "  {\"name\":\"python_interpreter\",\"description\":\"Execute Python code and return the output.\",\n",
    "   \"parameters\":{\"type\":\"object\",\"properties\":{\"code\":{\"type\":\"string\",\"description\":\"Python source code\"}},\"required\":[\"code\"]}},\n",
    "  {\"name\":\"web_search\",\"description\":\"Search the web for up-to-date information.\",\n",
    "   \"parameters\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query\"}},\"required\":[\"query\"]}},\n",
    "  {\"name\":\"translator\",\"description\":\"Translate text from one language to another.\",\n",
    "   \"parameters\":{\"type\":\"object\",\"properties\":{\"text\":{\"type\":\"string\",\"description\":\"Text to translate\"},\n",
    "    \"target_language\":{\"type\":\"string\",\"description\":\"Target language\"}},\"required\":[\"text\",\"target_language\"]}}\n",
    "]\n",
    "TOOL_NAMES = {t[\"name\"] for t in TOOLS}\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# LIQUID OFFICIAL FORMAT (per Maxime Labonne / docs.liquid.ai)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "SYS_PROMPT = f\"List of tools: {json.dumps(TOOLS)}\"\n",
    "\n",
    "# Compare with original Qwen-style prompt\n",
    "tool_json_pretty = json.dumps(TOOLS, indent=2)\n",
    "OLD_SYS_PROMPT = (\n",
    "    \"You are a helpful assistant with access to tools. \"\n",
    "    \"When a user request requires using a tool, generate a tool call \"\n",
    "    f\"between {TOOL_S} and {TOOL_E} tokens. Available tools:\\n\" + tool_json_pretty)\n",
    "\n",
    "print(f\"OLD system prompt: {len(OLD_SYS_PROMPT)} chars\")\n",
    "print(f\"NEW system prompt: {len(SYS_PROMPT)} chars\")\n",
    "print(f\"Reduction: {len(OLD_SYS_PROMPT) - len(SYS_PROMPT)} chars ({(1-len(SYS_PROMPT)/len(OLD_SYS_PROMPT))*100:.0f}%)\")\n",
    "print(f\"\\nNEW prompt preview:\\n{SYS_PROMPT[:200]}...\")\n",
    "\n",
    "def fmt(sample):\n",
    "    return [{\"role\":\"system\",\"content\":SYS_PROMPT},\n",
    "            {\"role\":\"user\",\"content\":sample[\"instruction\"]}]\n",
    "\n",
    "print(f\"\\nLiquid official format: {len(TOOLS)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5d23f",
   "metadata": {},
   "source": [
    "## 4 - Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a83c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fad3d702e94b92b85d8b0af0e8e6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94374f99077643bd8a53eb595428b9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad4b9ddbb594a30a9af33a4999ece76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b65a32157345d3b6dfa7229b64531a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10d99c80e3c468faf2000b55e292d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3462fa5b0c514bc085d8e30fec7d72ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c863462d014895be38d4ae96717be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45f9d4d5a594db2985f348a913f5a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiquidAI/LFM2.5-1.2B-Instruct (1170M params, 16 layers)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, dtype=torch.float16, device_map=\"auto\", trust_remote_code=True)\n",
    "model.eval()\n",
    "NUM_LAYERS = len(model.model.layers)\n",
    "print(f\"{MODEL_ID} ({sum(p.numel() for p in model.parameters())/1e6:.0f}M params, {NUM_LAYERS} layers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0c91f",
   "metadata": {},
   "source": [
    "## 4.5 - Verify Prompt Format\n",
    "Compare tokenized output of old vs new system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f125ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NEW (Liquid Official) ===\n",
      "<|startoftext|><|im_start|>system\n",
      "List of tools: [{\"name\": \"calculator\", \"description\": \"Evaluate a mathematical expression and return the numeric result.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}}, \"required\": [\"expression\"]}}, {\"name\": \"python_interpreter\", \"description\": \"Execute Python code and return the output.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"code\": {\"type\": \"string\", \"description\": \"Python source code\"}}, \"required\": [\"code\"]}}, {\"name\": \"web_search\", \"description\": \"Search the web for up-to-date information.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}}, {\"name\": \"translator\", \"description\": \"Translate text from one language to another.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"Text to translate\"}, \"target_language\": {\"type\": \"string\", \"description\": \"Target language\"}}, \"required\": [\"text\", \"target_language\"]}}]<|im_end|>\n",
      "<|im_start|>user\n",
      "Calculate 25% of $200<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Tokens: 289\n",
      "\n",
      "=== OLD (Qwen-style) ===\n",
      "<|startoftext|><|im_start|>system\n",
      "You are a helpful assistant with access to tools. When a user request requires using a tool, generate a tool call between <|tool_call_start|> and <|tool_call_end|> tokens. Available tools:\n",
      "[\n",
      "  {\n",
      "    \"name\": \"calculator\",\n",
      "    \"description\": \"Evaluate a mathematical expression and return the numeric result.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"expression\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Math expression\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"expression\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"python_interpreter\",\n",
      "    \"description\": \"Execute Python code and return the output.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"code\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Python source code\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"code\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"web_search\",\n",
      "    \"description\": \"Search the web for up-to-date information.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"query\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Search query\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"query\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"translator\",\n",
      "    \"description\": \"Translate text from one language to another.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"text\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Text to translate\"\n",
      "        },\n",
      "        \"target_language\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Target language\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"text\",\n",
      "        \"target_language\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "]<|im_end|>\n",
      "<|im_start|>user\n",
      "Calculate 25% of $200<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Tokens: 425\n",
      "\n",
      "=== V2 (apply_chat_template tools=) ===\n",
      "<|startoftext|><|im_start|>system\n",
      "List of tools: [{\"name\": \"calculator\", \"description\": \"Evaluate a mathematical expression and return the numeric result.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}}, \"required\": [\"expression\"]}}, {\"name\": \"python_interpreter\", \"description\": \"Execute Python code and return the output.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"code\": {\"type\": \"string\", \"description\": \"Python source code\"}}, \"required\": [\"code\"]}}, {\"name\": \"web_search\", \"description\": \"Search the web for up-to-date information.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}}, {\"name\": \"translator\", \"description\": \"Translate text from one language to another.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"text\": {\"type\": \"string\", \"description\": \"Text to translate\"}, \"target_language\": {\"type\": \"string\", \"description\": \"Target language\"}}, \"required\": [\"text\", \"target_language\"]}}]<|im_end|>\n",
      "<|im_start|>user\n",
      "Calculate 25% of $200<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Tokens: 289\n"
     ]
    }
   ],
   "source": [
    "# Show what the model actually sees with the new prompt\n",
    "test_msg = [{\"role\":\"system\",\"content\":SYS_PROMPT},\n",
    "            {\"role\":\"user\",\"content\":\"Calculate 25% of $200\"}]\n",
    "new_text = tokenizer.apply_chat_template(test_msg, tokenize=False, add_generation_prompt=True)\n",
    "print(\"=== NEW (Liquid Official) ===\")\n",
    "print(new_text)\n",
    "print(f\"\\nTokens: {len(tokenizer.encode(new_text))}\")\n",
    "\n",
    "test_msg_old = [{\"role\":\"system\",\"content\":OLD_SYS_PROMPT},\n",
    "                {\"role\":\"user\",\"content\":\"Calculate 25% of $200\"}]\n",
    "old_text = tokenizer.apply_chat_template(test_msg_old, tokenize=False, add_generation_prompt=True)\n",
    "print(\"\\n=== OLD (Qwen-style) ===\")\n",
    "print(old_text)\n",
    "print(f\"\\nTokens: {len(tokenizer.encode(old_text))}\")\n",
    "\n",
    "# Also test apply_chat_template with tools= parameter\n",
    "test_msg_v2 = [{\"role\":\"user\",\"content\":\"Calculate 25% of $200\"}]\n",
    "try:\n",
    "    v2_text = tokenizer.apply_chat_template(test_msg_v2, tools=TOOLS,\n",
    "                                            tokenize=False, add_generation_prompt=True)\n",
    "    print(\"\\n=== V2 (apply_chat_template tools=) ===\")\n",
    "    print(v2_text)\n",
    "    print(f\"\\nTokens: {len(tokenizer.encode(v2_text))}\")\n",
    "    V2_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"\\ntools= parameter not supported: {e}\")\n",
    "    V2_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35be3ca",
   "metadata": {},
   "source": [
    "## 5 - Hidden State Extraction\n",
    "Extracts last-token hidden states at all layers. Checkpointed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4632b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b910c68ba645cd8cf69c8350e55a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cal:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  save h_cal (40960KB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3783aeae6fa4153b72e76c6f29e5e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  save h_train (40960KB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea5d5affcc5408590200f7d62ec5878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  save h_valid (40960KB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043f71fc71794ff6be07d66a29436ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  save h_test (81920KB)\n",
      "All hidden states ready.\n"
     ]
    }
   ],
   "source": [
    "LAYERS = list(range(NUM_LAYERS))\n",
    "\n",
    "def extract_h(samples, tag):\n",
    "    cached = load_ckpt(f\"h_{tag}\")\n",
    "    if cached is not None: return cached\n",
    "    states = {l: [] for l in LAYERS}\n",
    "    hooks = []\n",
    "    def make_hook(li):\n",
    "        def fn(m, inp, out):\n",
    "            h = out[0] if isinstance(out, tuple) else out\n",
    "            states[li].append(h[:,-1,:].detach().cpu().float().numpy())\n",
    "        return fn\n",
    "    for l in LAYERS:\n",
    "        hooks.append(model.model.layers[l].register_forward_hook(make_hook(l)))\n",
    "    try:\n",
    "        for s in tqdm(samples, desc=tag):\n",
    "            text = tokenizer.apply_chat_template(fmt(s), tokenize=False, add_generation_prompt=True)\n",
    "            inp = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048).to(DEVICE)\n",
    "            with torch.no_grad(): model(**inp)\n",
    "            if DEVICE.type==\"cuda\": torch.cuda.empty_cache()\n",
    "    finally:\n",
    "        for h in hooks: h.remove()\n",
    "    result = {l: np.concatenate(states[l], axis=0) for l in LAYERS}\n",
    "    save_ckpt(f\"h_{tag}\", result)\n",
    "    return result\n",
    "\n",
    "cal_h   = extract_h(all_data[\"cal\"],   \"cal\")\n",
    "train_h = extract_h(all_data[\"train\"], \"train\")\n",
    "valid_h = extract_h(all_data[\"valid\"], \"valid\")\n",
    "test_h  = extract_h(all_data[\"test\"],  \"test\")\n",
    "\n",
    "cal_y   = np.array([s[\"label\"]  for s in all_data[\"cal\"]])\n",
    "cal_d   = np.array([s[\"domain\"] for s in all_data[\"cal\"]])\n",
    "train_y = np.array([s[\"label\"]  for s in all_data[\"train\"]])\n",
    "train_d = np.array([s[\"domain\"] for s in all_data[\"train\"]])\n",
    "valid_y = np.array([s[\"label\"]  for s in all_data[\"valid\"]])\n",
    "valid_d = np.array([s[\"domain\"] for s in all_data[\"valid\"]])\n",
    "test_y  = np.array([s[\"label\"]  for s in all_data[\"test\"]])\n",
    "test_d  = np.array([s[\"domain\"] for s in all_data[\"test\"]])\n",
    "print(\"All hidden states ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446dbf90",
   "metadata": {},
   "source": [
    "## 6 - Probe Sweep -> Optimal Layer L*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a2298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Layer  0 | AUC: 0.5432 | Acc: 0.5437\n",
      "  Layer  1 | AUC: 0.5432 | Acc: 0.5437\n",
      "  Layer  2 | AUC: 0.8767 | Acc: 0.7812\n",
      "  Layer  3 | AUC: 0.8739 | Acc: 0.7906\n",
      "  Layer  4 | AUC: 0.8663 | Acc: 0.7812\n",
      "  Layer  5 | AUC: 0.8837 | Acc: 0.7719\n",
      "  Layer  6 | AUC: 0.8837 | Acc: 0.7906\n",
      "  Layer  7 | AUC: 0.8964 | Acc: 0.8250\n",
      "  Layer  8 | AUC: 0.8826 | Acc: 0.7906\n",
      "  Layer  9 | AUC: 0.8847 | Acc: 0.7844\n",
      "  Layer 10 | AUC: 0.8807 | Acc: 0.7906\n",
      "  Layer 11 | AUC: 0.8853 | Acc: 0.7906\n",
      "  Layer 12 | AUC: 0.8833 | Acc: 0.7844\n",
      "  Layer 13 | AUC: 0.8805 | Acc: 0.7969\n",
      "  Layer 14 | AUC: 0.8841 | Acc: 0.8031\n",
      "  Layer 15 | AUC: 0.8733 | Acc: 0.7781\n",
      "\n",
      "L* = 7 (AUC=0.8964, plateau=1 layers)\n"
     ]
    }
   ],
   "source": [
    "aucs = {}\n",
    "for l in LAYERS:\n",
    "    sc = StandardScaler()\n",
    "    Xtr = sc.fit_transform(train_h[l]); Xva = sc.transform(valid_h[l])\n",
    "    p = LogisticRegression(max_iter=1000, C=1.0, solver=\"lbfgs\")\n",
    "    p.fit(Xtr, train_y)\n",
    "    auc = roc_auc_score(valid_y, p.predict_proba(Xva)[:,1])\n",
    "    acc = accuracy_score(valid_y, p.predict(Xva))\n",
    "    aucs[l] = auc\n",
    "    print(f\"  Layer {l:2d} | AUC: {auc:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "best_auc = max(aucs.values())\n",
    "candidates = [l for l in LAYERS if aucs[l] >= best_auc - 0.005]\n",
    "L_STAR = max(candidates)\n",
    "print(f\"\\nL* = {L_STAR} (AUC={aucs[L_STAR]:.4f}, plateau={len(candidates)} layers)\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "colors = ['#2196F3' if l < 10 else '#FF5722' for l in LAYERS]\n",
    "ax.bar(LAYERS, [aucs[l] for l in LAYERS], color=colors, alpha=0.85)\n",
    "ax.axvline(L_STAR, color='gold', lw=2, ls='--', label=f'L*={L_STAR}')\n",
    "ax.set_xlabel(\"Layer\"); ax.set_ylabel(\"AUC\"); ax.set_title(\"Probe Sweep - Liquid Prompt (Blue=LIV, Red=GQA)\")\n",
    "ax.legend(); ax.set_xticks(LAYERS); plt.tight_layout()\n",
    "plt.savefig(OUT/\"probe_sweep.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750502cf",
   "metadata": {},
   "source": [
    "## 7 - Steering Vector Construction (CAL split only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7850e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  math         cos(v_d, v_g) = 0.7037\n",
      "  code         cos(v_d, v_g) = 0.4614\n",
      "  search       cos(v_d, v_g) = 0.7074\n",
      "  translation  cos(v_d, v_g) = 0.6359\n",
      "\n",
      "Cross-domain cosines:\n",
      "  math<->code: -0.0143\n",
      "  math<->search: 0.3188\n",
      "  math<->translation: 0.3523\n",
      "  code<->search: 0.2368\n",
      "  code<->translation: 0.0882\n",
      "  search<->translation: 0.1842\n",
      "Vectors built from CAL.\n"
     ]
    }
   ],
   "source": [
    "H = cal_h[L_STAR]\n",
    "tool_m = cal_y == 1\n",
    "v_global = H[tool_m].mean(0) - H[~tool_m].mean(0)\n",
    "v_global = v_global / (np.linalg.norm(v_global) + 1e-8)\n",
    "\n",
    "d_vecs = {}\n",
    "for d in DOMAINS:\n",
    "    dm = cal_d == d\n",
    "    vd = H[dm & tool_m].mean(0) - H[dm & ~tool_m].mean(0)\n",
    "    vd = vd / (np.linalg.norm(vd) + 1e-8)\n",
    "    d_vecs[d] = vd\n",
    "    print(f\"  {d:12s} cos(v_d, v_g) = {np.dot(vd, v_global):.4f}\")\n",
    "\n",
    "print(\"\\nCross-domain cosines:\")\n",
    "for i,d1 in enumerate(DOMAINS):\n",
    "    for d2 in DOMAINS[i+1:]:\n",
    "        print(f\"  {d1}<->{d2}: {np.dot(d_vecs[d1], d_vecs[d2]):.4f}\")\n",
    "print(\"Vectors built from CAL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625a5ff",
   "metadata": {},
   "source": [
    "## 8 - Router & Probes (TRAIN split only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5b0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Router train acc: 1.0000\n",
      "  Probe 'math' train acc: 1.0000\n",
      "  Probe 'code' train acc: 1.0000\n",
      "  Probe 'search' train acc: 1.0000\n",
      "  Probe 'translation' train acc: 1.0000\n",
      "  Router valid acc: 0.7656\n",
      "  Probe 'math' valid acc: 0.9000\n",
      "  Probe 'code' valid acc: 0.6875\n",
      "  Probe 'search' valid acc: 0.9500\n",
      "  Probe 'translation' valid acc: 1.0000\n",
      "Router & probes trained on TRAIN.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(train_h[L_STAR])\n",
    "d2i = {d:i for i,d in enumerate(DOMAINS)}\n",
    "i2d = {i:d for d,i in d2i.items()}\n",
    "\n",
    "router = LogisticRegression(max_iter=2000, C=1.0, solver=\"lbfgs\", multi_class=\"multinomial\")\n",
    "router.fit(X_tr, np.array([d2i[d] for d in train_d]))\n",
    "print(f\"  Router train acc: {accuracy_score([d2i[d] for d in train_d], router.predict(X_tr)):.4f}\")\n",
    "\n",
    "probes = {}\n",
    "for d in DOMAINS:\n",
    "    m = train_d == d; Xd = X_tr[m]; yd = train_y[m]\n",
    "    if len(np.unique(yd)) < 2:\n",
    "        print(f\"  Probe '{d}': only one class, skipping\"); continue\n",
    "    p = LogisticRegression(max_iter=1000, C=1.0, solver=\"lbfgs\"); p.fit(Xd, yd)\n",
    "    probes[d] = p\n",
    "    print(f\"  Probe '{d}' train acc: {accuracy_score(yd, p.predict(Xd)):.4f}\")\n",
    "\n",
    "X_va = scaler.transform(valid_h[L_STAR])\n",
    "print(f\"  Router valid acc: {accuracy_score([d2i[d] for d in valid_d], router.predict(X_va)):.4f}\")\n",
    "for d in DOMAINS:\n",
    "    if d not in probes: continue\n",
    "    m = valid_d == d\n",
    "    if m.sum()==0: continue\n",
    "    print(f\"  Probe '{d}' valid acc: {accuracy_score(valid_y[m], probes[d].predict(X_va[m])):.4f}\")\n",
    "print(\"Router & probes trained on TRAIN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36d476",
   "metadata": {},
   "source": [
    "## 9 - Hyperparameter Tuning on VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ac605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha sweep:\n",
      "  a=   1 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   2 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   3 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   4 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   5 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   6 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   7 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=   8 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=  10 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=  12 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=  15 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  a=  20 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  Best alpha = 1\n",
      "\n",
      "tau sweep:\n",
      "  tau=0.50 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  tau=0.55 | F1=0.8075 Prec=0.8025 Rec=0.8125 FPR=0.2000\n",
      "  tau=0.60 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  tau=0.65 | F1=0.8063 Prec=0.8063 Rec=0.8063 FPR=0.1938\n",
      "  tau=0.70 | F1=0.8013 Prec=0.8089 Rec=0.7937 FPR=0.1875\n",
      "  Best tau = 0.5\n",
      "\n",
      "beta sweep:\n",
      "  beta=0.0 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=0.1 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=0.2 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=0.3 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=0.5 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=0.7 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  beta=1.0 | F1=0.8111 Prec=0.8037 Rec=0.8187 FPR=0.2000\n",
      "  Best beta = 0.0\n",
      "  Final: alpha=1, tau=0.5, beta=0.0\n"
     ]
    }
   ],
   "source": [
    "def eval_hidden(alpha, tau, beta, h, y, d_arr):\n",
    "    X = scaler.transform(h); preds = []\n",
    "    for i in range(len(y)):\n",
    "        xi = X[i:i+1]\n",
    "        dom = i2d[router.predict(xi)[0]]\n",
    "        if dom not in probes: preds.append(0); continue\n",
    "        pt = probes[dom].predict_proba(xi)[0,1]\n",
    "        gate = 1 if pt >= tau else (-1 if pt <= 1-tau else 0)\n",
    "        preds.append(1 if gate == 1 else 0)\n",
    "    preds = np.array(preds)\n",
    "    return {\"f1\": f1_score(y, preds, zero_division=0),\n",
    "            \"precision\": precision_score(y, preds, zero_division=0),\n",
    "            \"recall\": recall_score(y, preds, zero_division=0),\n",
    "            \"fpr\": (preds[y==0]==1).mean() if (y==0).sum()>0 else 0,\n",
    "            \"accuracy\": accuracy_score(y, preds)}\n",
    "\n",
    "print(\"alpha sweep:\")\n",
    "alpha_res = []\n",
    "for a in [1,2,3,4,5,6,7,8,10,12,15,20]:\n",
    "    m = eval_hidden(a, 0.60, 0.3, valid_h[L_STAR], valid_y, valid_d)\n",
    "    m[\"a\"] = a; alpha_res.append(m)\n",
    "    print(f\"  a={a:4.0f} | F1={m['f1']:.4f} Prec={m['precision']:.4f} Rec={m['recall']:.4f} FPR={m['fpr']:.4f}\")\n",
    "ALPHA = max(alpha_res, key=lambda x: x[\"f1\"])[\"a\"]\n",
    "print(f\"  Best alpha = {ALPHA}\")\n",
    "\n",
    "print(\"\\ntau sweep:\")\n",
    "tau_res = []\n",
    "for t in [0.50, 0.55, 0.60, 0.65, 0.70]:\n",
    "    m = eval_hidden(ALPHA, t, 0.3, valid_h[L_STAR], valid_y, valid_d)\n",
    "    m[\"t\"] = t; tau_res.append(m)\n",
    "    print(f\"  tau={t:.2f} | F1={m['f1']:.4f} Prec={m['precision']:.4f} Rec={m['recall']:.4f} FPR={m['fpr']:.4f}\")\n",
    "TAU = max(tau_res, key=lambda x: x[\"f1\"])[\"t\"]\n",
    "print(f\"  Best tau = {TAU}\")\n",
    "\n",
    "print(\"\\nbeta sweep:\")\n",
    "beta_res = []\n",
    "for b in [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0]:\n",
    "    m = eval_hidden(ALPHA, TAU, b, valid_h[L_STAR], valid_y, valid_d)\n",
    "    m[\"b\"] = b; beta_res.append(m)\n",
    "    print(f\"  beta={b:.1f} | F1={m['f1']:.4f} Prec={m['precision']:.4f} Rec={m['recall']:.4f} FPR={m['fpr']:.4f}\")\n",
    "BETA = max(beta_res, key=lambda x: x[\"f1\"])[\"b\"]\n",
    "print(f\"  Best beta = {BETA}\\n  Final: alpha={ALPHA}, tau={TAU}, beta={BETA}\")\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(15,4))\n",
    "axes[0].plot([r[\"a\"] for r in alpha_res],[r[\"f1\"] for r in alpha_res],'o-',color='#2196F3')\n",
    "axes[0].axvline(ALPHA,color='gold',ls='--'); axes[0].set_xlabel(\"alpha\"); axes[0].set_ylabel(\"F1\")\n",
    "axes[1].plot([r[\"t\"] for r in tau_res],[r[\"f1\"] for r in tau_res],'o-',color='#FF5722')\n",
    "axes[1].axvline(TAU,color='gold',ls='--'); axes[1].set_xlabel(\"tau\"); axes[1].set_ylabel(\"F1\")\n",
    "axes[2].plot([r[\"b\"] for r in beta_res],[r[\"f1\"] for r in beta_res],'o-',color='#4CAF50')\n",
    "axes[2].axvline(BETA,color='gold',ls='--'); axes[2].set_xlabel(\"beta\"); axes[2].set_ylabel(\"F1\")\n",
    "plt.tight_layout(); plt.savefig(OUT/\"hp_sweep.png\",dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f610882",
   "metadata": {},
   "source": [
    "## 10 - TEST Evaluation\n",
    "Trigger P/R/F1/FPR + Success Precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022020aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on TEST set (this takes ~10 min)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5a2d1b6be645cf901d0f32d0d49648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST eval:   0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "[Baseline (Liquid Prompt, no ASA)]\n",
      "  Trig P/R/F1: 0.4927 / 0.6312 / 0.5534\n",
      "  FPR: 0.6500  Acc: 0.4906\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n",
      "\n",
      "[ASA (Liquid Prompt)]\n",
      "  Trig P/R/F1: 0.6476 / 0.2125 / 0.3200\n",
      "  FPR: 0.1156  Acc: 0.5484\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n",
      "\n",
      "Per-Domain ASA:\n",
      "\n",
      "[ASA/math]\n",
      "  Trig P/R/F1: 0.3636 / 0.1500 / 0.2124\n",
      "  FPR: 0.2625  Acc: 0.4437\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n",
      "\n",
      "[ASA/code]\n",
      "  Trig P/R/F1: 0.5833 / 0.1750 / 0.2692\n",
      "  FPR: 0.1250  Acc: 0.5250\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n",
      "\n",
      "[ASA/search]\n",
      "  Trig P/R/F1: 0.8780 / 0.4500 / 0.5950\n",
      "  FPR: 0.0625  Acc: 0.6937\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n",
      "\n",
      "[ASA/translation]\n",
      "  Trig P/R/F1: 0.8571 / 0.0750 / 0.1379\n",
      "  FPR: 0.0125  Acc: 0.5312\n",
      "  Success P: JSON=0.0000 Schema=0.0000 Args=0.0000\n"
     ]
    }
   ],
   "source": [
    "def parse_tool_call(text):\n",
    "    if TOOL_S not in text: return None\n",
    "    try:\n",
    "        s = text.index(TOOL_S) + len(TOOL_S)\n",
    "        e = text.index(TOOL_E) if TOOL_E in text else len(text)\n",
    "        raw = text[s:e].strip()\n",
    "        try: obj = json.loads(raw); json_ok = True\n",
    "        except: obj = None; json_ok = False\n",
    "        if not json_ok:\n",
    "            try: obj = ast.literal_eval(raw); json_ok = True\n",
    "            except: pass\n",
    "        if obj and isinstance(obj, dict):\n",
    "            name = obj.get(\"name\",\"\")\n",
    "            args = obj.get(\"arguments\", obj.get(\"args\", {}))\n",
    "            return {\"json_valid\":True,\n",
    "                    \"schema_ok\": name in TOOL_NAMES,\n",
    "                    \"args_ok\": isinstance(args,dict) and len(args)>0 and all(v!=\"\" for v in args.values()),\n",
    "                    \"name\": name, \"args\": args}\n",
    "        return {\"json_valid\": json_ok, \"schema_ok\": False, \"args_ok\": False, \"name\":\"\", \"args\":{}}\n",
    "    except: return {\"json_valid\":False, \"schema_ok\":False, \"args_ok\":False, \"name\":\"\", \"args\":{}}\n",
    "\n",
    "def generate(messages, hook_fn=None, layer=None, max_tok=256):\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inp = {k:v.to(DEVICE) for k,v in inp.items()}\n",
    "    hook = None\n",
    "    if hook_fn and layer is not None:\n",
    "        hook = model.model.layers[layer].register_forward_hook(hook_fn)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(**inp, max_new_tokens=max_tok, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "        return tokenizer.decode(out[0][inp[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
    "    finally:\n",
    "        if hook: hook.remove()\n",
    "\n",
    "# ASA hook\n",
    "_injected = False; _info = {}\n",
    "def asa_hook(module, inp, out):\n",
    "    global _injected, _info\n",
    "    if _injected: return out\n",
    "    h = out[0] if isinstance(out, tuple) else out\n",
    "    rest = out[1:] if isinstance(out, tuple) else None\n",
    "    hl = h[:,-1,:].detach().cpu().float().numpy()\n",
    "    hs = scaler.transform(hl)\n",
    "    dom = i2d[router.predict(hs)[0]]\n",
    "    pt = probes[dom].predict_proba(hs)[0,1] if dom in probes else 0.5\n",
    "    gate = 1 if pt >= TAU else (-1 if pt <= 1-TAU else 0)\n",
    "    _info = {\"domain\":dom, \"p_tool\":float(pt), \"gate\":gate}\n",
    "    _injected = True\n",
    "    if gate == 0: return out\n",
    "    vd = d_vecs[dom]; v = (1-BETA)*vd + BETA*v_global\n",
    "    v = v / (np.linalg.norm(v)+1e-8)\n",
    "    vt = torch.tensor(v, dtype=torch.float16).to(h.device)\n",
    "    hn = h.clone(); hn[:,-1,:] = h[:,-1,:] + gate * ALPHA * vt\n",
    "    return (hn,)+rest if rest else hn\n",
    "\n",
    "print(\"Evaluating on TEST set (this takes ~10 min)...\")\n",
    "bl_res, asa_res = [], []\n",
    "test_samples = all_data[\"test\"]\n",
    "\n",
    "for s in tqdm(test_samples, desc=\"TEST eval\"):\n",
    "    msgs = fmt(s)\n",
    "    bl_out = generate(msgs)\n",
    "    bl_trig = TOOL_S in bl_out\n",
    "    bl_parsed = parse_tool_call(bl_out) if bl_trig else None\n",
    "    bl_res.append({\"label\":s[\"label\"],\"domain\":s[\"domain\"],\"triggered\":bl_trig,\"parsed\":bl_parsed})\n",
    "    global _injected, _info\n",
    "    _injected = False; _info = {}\n",
    "    asa_out = generate(msgs, hook_fn=asa_hook, layer=L_STAR)\n",
    "    asa_trig = TOOL_S in asa_out\n",
    "    asa_parsed = parse_tool_call(asa_out) if asa_trig else None\n",
    "    asa_res.append({\"label\":s[\"label\"],\"domain\":s[\"domain\"],\"triggered\":asa_trig,\"parsed\":asa_parsed,\"info\":_info})\n",
    "    if DEVICE.type==\"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "def compute_metrics(results, name):\n",
    "    y = np.array([r[\"label\"] for r in results])\n",
    "    p = np.array([1 if r[\"triggered\"] else 0 for r in results])\n",
    "    m = {\"precision\": precision_score(y,p,zero_division=0),\n",
    "         \"recall\": recall_score(y,p,zero_division=0),\n",
    "         \"f1\": f1_score(y,p,zero_division=0),\n",
    "         \"fpr\": (p[y==0]==1).mean() if (y==0).sum()>0 else 0,\n",
    "         \"accuracy\": accuracy_score(y,p)}\n",
    "    triggered = [r for r in results if r[\"triggered\"] and r[\"parsed\"]]\n",
    "    if triggered:\n",
    "        m[\"succ_json\"] = np.mean([r[\"parsed\"][\"json_valid\"] for r in triggered])\n",
    "        m[\"succ_schema\"] = np.mean([r[\"parsed\"][\"schema_ok\"] for r in triggered])\n",
    "        m[\"succ_args\"] = np.mean([r[\"parsed\"][\"args_ok\"] for r in triggered])\n",
    "    else:\n",
    "        m[\"succ_json\"] = m[\"succ_schema\"] = m[\"succ_args\"] = 0.0\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(f\"  Trig P/R/F1: {m['precision']:.4f} / {m['recall']:.4f} / {m['f1']:.4f}\")\n",
    "    print(f\"  FPR: {m['fpr']:.4f}  Acc: {m['accuracy']:.4f}\")\n",
    "    print(f\"  Success P: JSON={m['succ_json']:.4f} Schema={m['succ_schema']:.4f} Args={m['succ_args']:.4f}\")\n",
    "    return m\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "bl_m = compute_metrics(bl_res, \"Baseline (Liquid Prompt, no ASA)\")\n",
    "asa_m = compute_metrics(asa_res, \"ASA (Liquid Prompt)\")\n",
    "\n",
    "print(\"\\nPer-Domain ASA:\")\n",
    "for d in DOMAINS:\n",
    "    dr = [r for r in asa_res if r[\"domain\"]==d]\n",
    "    if dr: compute_metrics(dr, f\"ASA/{d}\")\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "names = [\"Precision\",\"Recall\",\"F1\"]\n",
    "bv = [bl_m[\"precision\"],bl_m[\"recall\"],bl_m[\"f1\"]]\n",
    "av = [asa_m[\"precision\"],asa_m[\"recall\"],asa_m[\"f1\"]]\n",
    "x = np.arange(len(names))\n",
    "ax.bar(x-0.2,bv,0.35,label=\"Baseline (Liquid)\",color=\"#90A4AE\")\n",
    "ax.bar(x+0.2,av,0.35,label=\"ASA (Liquid)\",color=\"#FF5722\")\n",
    "ax.set_xticks(x); ax.set_xticklabels(names); ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Baseline vs ASA: Liquid Official Prompt\"); ax.legend(); ax.set_ylim(0,1.05)\n",
    "plt.tight_layout(); plt.savefig(OUT/\"baseline_vs_asa.png\",dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080aa646",
   "metadata": {},
   "source": [
    "## 11 - Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64acc84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ablation on TEST hidden states...\n",
      "Variant         |     F1 |   Prec |    Rec |    FPR\n",
      "-------------------------------------------------------\n",
      "full            | 0.8092 | 0.7970 | 0.8219 | 0.2094\n",
      "no_gate         | 0.6667 | 0.5000 | 1.0000 | 1.0000\n",
      "global_only     | 0.8092 | 0.7970 | 0.8219 | 0.2094\n",
      "domain_only     | 0.8092 | 0.7970 | 0.8219 | 0.2094\n",
      "\n",
      "Ablation complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running ablation on TEST hidden states...\")\n",
    "test_H = test_h[L_STAR]\n",
    "\n",
    "def ablation_eval(variant):\n",
    "    X = scaler.transform(test_H); preds = []\n",
    "    for i in range(len(test_y)):\n",
    "        xi = X[i:i+1]\n",
    "        dom = i2d[router.predict(xi)[0]]\n",
    "        if dom not in probes: preds.append(0); continue\n",
    "        pt = probes[dom].predict_proba(xi)[0,1]\n",
    "        if variant == \"full\":\n",
    "            gate = 1 if pt >= TAU else (-1 if pt <= 1-TAU else 0)\n",
    "        elif variant == \"no_gate\":\n",
    "            gate = 1\n",
    "        elif variant == \"global_only\":\n",
    "            gate = 1 if pt >= TAU else (-1 if pt <= 1-TAU else 0)\n",
    "        elif variant == \"domain_only\":\n",
    "            gate = 1 if pt >= TAU else (-1 if pt <= 1-TAU else 0)\n",
    "        else:\n",
    "            gate = 0\n",
    "        preds.append(1 if gate == 1 else 0)\n",
    "    preds = np.array(preds)\n",
    "    return {\"f1\": f1_score(test_y,preds,zero_division=0),\n",
    "            \"precision\": precision_score(test_y,preds,zero_division=0),\n",
    "            \"recall\": recall_score(test_y,preds,zero_division=0),\n",
    "            \"fpr\": (preds[test_y==0]==1).mean() if (test_y==0).sum()>0 else 0}\n",
    "\n",
    "variants = [\"full\",\"no_gate\",\"global_only\",\"domain_only\"]\n",
    "print(f\"{'Variant':15s} | {'F1':>6s} | {'Prec':>6s} | {'Rec':>6s} | {'FPR':>6s}\")\n",
    "print(\"-\"*55)\n",
    "abl_results = {}\n",
    "for v in variants:\n",
    "    m = ablation_eval(v)\n",
    "    abl_results[v] = m\n",
    "    print(f\"{v:15s} | {m['f1']:.4f} | {m['precision']:.4f} | {m['recall']:.4f} | {m['fpr']:.4f}\")\n",
    "print(\"\\nAblation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534185bf",
   "metadata": {},
   "source": [
    "## 12 - Save Assets, Demo & Prompt Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d245849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets saved: outputs_liquid/asa_assets (221 KB)\n",
      "\n",
      "======================================================================\n",
      "  PROMPT FORMAT COMPARISON: Qwen-style vs Liquid Official\n",
      "======================================================================\n",
      "\n",
      "  BASELINE comparison:\n",
      "  Metric         | Qwen-style |     Liquid |     Change\n",
      "  ----------------------------------------------------\n",
      "  precision      |     0.4959 |     0.4927 | -0.0032 v\n",
      "  recall         |     0.5656 |     0.6312 | +0.0656 ^\n",
      "  f1             |     0.5285 |     0.5534 | +0.0249 ^\n",
      "  fpr            |     0.5750 |     0.6500 | +0.0750 ^\n",
      "  accuracy       |     0.4953 |     0.4906 | -0.0047 v\n",
      "\n",
      "  ASA comparison:\n",
      "  Metric         | Qwen-style |     Liquid |     Change\n",
      "  ----------------------------------------------------\n",
      "  precision      |     0.7591 |     0.6476 | -0.1115 v\n",
      "  recall         |     0.5219 |     0.2125 | -0.3094 v\n",
      "  f1             |     0.6185 |     0.3200 | -0.2985 v\n",
      "  fpr            |     0.1656 |     0.1156 | -0.0500 v\n",
      "  accuracy       |     0.6781 |     0.5484 | -0.1297 v\n",
      "\n",
      "======================================================================\n",
      "  DEMO: Baseline vs ASA (Liquid Prompt)\n",
      "======================================================================\n",
      "\n",
      "[TOOL] Calculate the monthly cost of a house if the monthly payment is 2000$ and the in\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      TRIGGERED (dom=math, p=0.996, gate=+1)\n",
      "\n",
      "[TOOL] How many teaspoons are in 1/4 cup?\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      no trigger (dom=math, p=0.930, gate=+1)\n",
      "\n",
      "[NO-TOOL] Construct an analogy to explain the function of a capacitor.\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      TRIGGERED (dom=math, p=0.000, gate=-1)\n",
      "\n",
      "[NO-TOOL] Rewrite the sentence to make it more succinct: The temperature of the air outsid\n",
      "  Baseline: no trigger\n",
      "  ASA:      no trigger (dom=code, p=0.997, gate=+1)\n",
      "\n",
      "[TOOL] Create a program to calculate the area of a triangle given three sides.\n",
      "3, 4, 5\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      TRIGGERED (dom=code, p=0.998, gate=+1)\n",
      "\n",
      "[NO-TOOL] Provide an original analogy to compare a computer to.\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      no trigger (dom=search, p=0.002, gate=-1)\n",
      "\n",
      "[TOOL] Calculate the average rating for this product using the following reviews.\n",
      "Revie\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      no trigger (dom=math, p=0.996, gate=+1)\n",
      "\n",
      "[TOOL] Calculate the month number given the date: August 24\n",
      "  Baseline: TRIGGERED\n",
      "  ASA:      no trigger (dom=math, p=0.995, gate=+1)\n",
      "\n",
      "\n",
      "DONE! L*=7, alpha=1, tau=0.5, beta=0.0\n",
      "Baseline FPR: 0.5750 (Qwen) -> 0.6500 (Liquid)\n",
      "ASA FPR:      0.1656 (Qwen) -> 0.1156 (Liquid)\n",
      "Baseline F1:  0.5285 (Qwen) -> 0.5534 (Liquid)\n",
      "ASA F1:       0.6185 (Qwen) -> 0.3200 (Liquid)\n"
     ]
    }
   ],
   "source": [
    "# Save assets\n",
    "assets = OUT/\"asa_assets\"; assets.mkdir(exist_ok=True)\n",
    "vecs_save = {\"global\": v_global}; vecs_save.update(d_vecs)\n",
    "np.savez(assets/\"steering_vectors.npz\", **vecs_save)\n",
    "with open(assets/\"router.pkl\",\"wb\") as f: pickle.dump(router,f)\n",
    "with open(assets/\"probes.pkl\",\"wb\") as f: pickle.dump(probes,f)\n",
    "with open(assets/\"scaler.pkl\",\"wb\") as f: pickle.dump(scaler,f)\n",
    "config = {\"model\": MODEL_ID, \"L_star\": int(L_STAR), \"alpha\": float(ALPHA),\n",
    "          \"tau\": float(TAU), \"beta\": float(BETA), \"domains\": DOMAINS,\n",
    "          \"prompt_format\": \"liquid_official\",\n",
    "          \"system_prompt\": SYS_PROMPT[:100] + \"...\",\n",
    "          \"probe_aucs\": {str(k):float(v) for k,v in aucs.items()},\n",
    "          \"test_baseline\": {k:float(v) for k,v in bl_m.items()},\n",
    "          \"test_asa\": {k:float(v) for k,v in asa_m.items()}}\n",
    "with open(assets/\"config.json\",\"w\") as f: json.dump(config,f,indent=2)\n",
    "kb = sum(f.stat().st_size for f in assets.iterdir())/1024\n",
    "print(f\"Assets saved: {assets} ({kb:.0f} KB)\")\n",
    "\n",
    "# COMPARISON TABLE\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  PROMPT FORMAT COMPARISON: Qwen-style vs Liquid Official\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "orig = {\"precision\": 0.4959, \"recall\": 0.5656, \"f1\": 0.5285, \"fpr\": 0.5750, \"accuracy\": 0.4953}\n",
    "orig_asa = {\"precision\": 0.7591, \"recall\": 0.5219, \"f1\": 0.6185, \"fpr\": 0.1656, \"accuracy\": 0.6781}\n",
    "\n",
    "print(\"\\n  BASELINE comparison:\")\n",
    "print(\"  %-14s | %10s | %10s | %10s\" % (\"Metric\", \"Qwen-style\", \"Liquid\", \"Change\"))\n",
    "print(\"  \" + \"-\"*52)\n",
    "for metric in [\"precision\", \"recall\", \"f1\", \"fpr\", \"accuracy\"]:\n",
    "    old_bl = orig[metric]\n",
    "    new_bl = bl_m[metric]\n",
    "    delta = new_bl - old_bl\n",
    "    arrow = \"^\" if delta > 0 else (\"v\" if delta < 0 else \"=\")\n",
    "    print(\"  %-14s | %10.4f | %10.4f | %+.4f %s\" % (metric, old_bl, new_bl, delta, arrow))\n",
    "\n",
    "print(\"\\n  ASA comparison:\")\n",
    "print(\"  %-14s | %10s | %10s | %10s\" % (\"Metric\", \"Qwen-style\", \"Liquid\", \"Change\"))\n",
    "print(\"  \" + \"-\"*52)\n",
    "for metric in [\"precision\", \"recall\", \"f1\", \"fpr\", \"accuracy\"]:\n",
    "    old_asa = orig_asa[metric]\n",
    "    new_asa = asa_m[metric]\n",
    "    delta = new_asa - old_asa\n",
    "    arrow = \"^\" if delta > 0 else (\"v\" if delta < 0 else \"=\")\n",
    "    print(\"  %-14s | %10.4f | %10.4f | %+.4f %s\" % (metric, old_asa, new_asa, delta, arrow))\n",
    "\n",
    "# Demo\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n  DEMO: Baseline vs ASA (Liquid Prompt)\\n\" + \"=\"*70)\n",
    "demos = test_samples[:8]\n",
    "for s in demos:\n",
    "    msgs = fmt(s)\n",
    "    bl = generate(msgs)\n",
    "    _injected = False; _info = {}\n",
    "    asa_out = generate(msgs, hook_fn=asa_hook, layer=L_STAR)\n",
    "    label = \"TOOL\" if s[\"label\"]==1 else \"NO-TOOL\"\n",
    "    gs = {1:\"+1\",-1:\"-1\",0:\"0\"}.get(_info.get(\"gate\",0),\"?\")\n",
    "    print(f\"\\n[{label}] {s['instruction'][:80]}\")\n",
    "    print(f\"  Baseline: {'TRIGGERED' if TOOL_S in bl else 'no trigger'}\")\n",
    "    print(f\"  ASA:      {'TRIGGERED' if TOOL_S in asa_out else 'no trigger'} \"\n",
    "          f\"(dom={_info.get('domain','?')}, p={_info.get('p_tool',0):.3f}, gate={gs})\")\n",
    "    if DEVICE.type==\"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n\\nDONE! L*={L_STAR}, alpha={ALPHA}, tau={TAU}, beta={BETA}\")\n",
    "print(f\"Baseline FPR: {orig['fpr']:.4f} (Qwen) -> {bl_m['fpr']:.4f} (Liquid)\")\n",
    "print(f\"ASA FPR:      {orig_asa['fpr']:.4f} (Qwen) -> {asa_m['fpr']:.4f} (Liquid)\")\n",
    "print(f\"Baseline F1:  {orig['f1']:.4f} (Qwen) -> {bl_m['f1']:.4f} (Liquid)\")\n",
    "print(f\"ASA F1:       {orig_asa['f1']:.4f} (Qwen) -> {asa_m['f1']:.4f} (Liquid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999cc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
