# ASA Ã— LFM2.5-1.2B-Instruct

**í•™ìŠµ ì—†ì´ ë„êµ¬ í˜¸ì¶œ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í™œì„±í™” ìŠ¤í‹°ì–´ë§**

[ğŸ‡ºğŸ‡¸ English Version](README.md)

---

## ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **ASA (Activation Steering Adapter)** ê¸°ë²•ì„ [LiquidAI/LFM2.5-1.2B-Instruct](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct) ëª¨ë¸ì— ì ìš©í•©ë‹ˆë‹¤.

LFM2.5ëŠ” 10ê°œ LIV ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ + 6ê°œ GQA ì–´í…ì…˜ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ëœ **1.17B íŒŒë¼ë¯¸í„° í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸**ì…ë‹ˆë‹¤.

ASAëŠ” **ëª¨ë¸ ì¬í•™ìŠµ ì—†ì´** ì¶”ë¡  ì‹œì ì—ì„œ ë„êµ¬ í˜¸ì¶œ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ë©°, ì¶”ê°€ ì—ì…‹ í¬ê¸°ëŠ” ë‹¨ ~221KBì…ë‹ˆë‹¤.

> ğŸ“„ ë…¼ë¬¸: [ASA: Training-Free Representation Engineering for Tool-Calling Agents](https://arxiv.org/abs/2602.04935)

## ì‹¤í—˜ ê²°ê³¼

[Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) ê³µê°œ ë°ì´í„°ì…‹ì—ì„œ ë„ë©”ì¸ë³„ í•„í„°ë§ìœ¼ë¡œ êµ¬ì¶•í•œ **1,600 ìƒ˜í”Œ ë²¤ì¹˜ë§ˆí¬**ì—ì„œ í‰ê°€. ë…¼ë¬¸ í”„ë¡œí† ì½œ ì¤€ìˆ˜ (greedy ë””ì½”ë”©, strict `<|tool_call_start|>` íŠ¸ë¦¬ê±° ê°ì§€, ë¶„ë¦¬ëœ ë°ì´í„° ë¶„í• ).

### Baseline vs ASA (TEST, 640 ìƒ˜í”Œ)

| ë©”íŠ¸ë¦­ | Baseline | ASA | ë³€í™” |
|--------|----------|-----|------|
| **Trigger Precision** | 0.4959 | **0.7591** | +53% â†‘ |
| **Trigger Recall** | 0.5656 | 0.5219 | -8% â†“ |
| **Trigger F1** | 0.5285 | **0.6185** | +17% â†‘ |
| **FPR (ì˜¤íƒë¥ )** | 0.5750 | **0.1656** | **-71%** â†“â†“ |
| **Accuracy** | 0.4953 | **0.6781** | +37% â†‘ |

**í•µì‹¬ ë°œê²¬:** ë² ì´ìŠ¤ë¼ì¸ì€ non-tool ì§ˆë¬¸ì˜ 57.5%ì—ì„œ ì˜ëª» toolì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤. ASA ì ìš© í›„ 16.6%ë¡œ 71% ê°ì†Œ.

### ë„ë©”ì¸ë³„ (ASA)

| ë„ë©”ì¸ | F1 | Precision | Recall | FPR |
|--------|----|-----------|--------|-----|
| ë²ˆì—­ | **0.9262** | 1.0000 | 0.8625 | 0.0000 |
| ìˆ˜í•™ | 0.7273 | 0.7568 | 0.7000 | 0.2250 |
| ê²€ìƒ‰ | 0.5410 | 0.7857 | 0.4125 | 0.1125 |
| ì½”ë“œ | 0.1565 | 0.2571 | 0.1125 | 0.3250 |

### Ablation ì—°êµ¬ (ë…¼ë¬¸ Â§4.3)

| ë³€í˜• | F1 | FPR | ì˜ë¯¸ |
|------|-----|-----|------|
| **Full ASA** | **0.8054** | 0.2375 | ìµœì  ê· í˜• |
| No Gate | 0.6667 | **1.0000** | ê²Œì´íŠ¸ê°€ í•µì‹¬ ì•ˆì „ì¥ì¹˜ |
| Global Only | 0.8054 | 0.2375 | ê°•ë ¥í•œ ê¸°ë³¸ ë°©í–¥ |
| Domain Only | 0.8054 | 0.2375 | ë„ë©”ì¸ë³„ ë¼ìš°íŒ… |

### íŒŒì´í”„ë¼ì¸ ì„¤ì •

| íŒŒë¼ë¯¸í„° | ê°’ |
|----------|-----|
| ìµœì  ë ˆì´ì–´ L* | **12** (GQA ë¸”ë¡) |
| Probe AUC at L* | 0.8810 |
| Î± (ìŠ¤í‹°ì–´ë§ ê°•ë„) | 1.0 |
| Ï„ (ì‹ ë¢° ì„ê³„ê°’) | 0.50 |
| Î² (MoV ê¸€ë¡œë²Œ ê°€ì¤‘ì¹˜) | 0.0 |
| ì—ì…‹ í¬ê¸° | 221 KB |

### í•œê³„

- **Success Precision = 0**: LFM2.5ëŠ” tool callì„ bracket í˜•ì‹(`[func(args)]`)ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ”ë°, JSON íŒŒì„œë¡œ ê²€ì¦í•˜ë¯€ë¡œ 0ì´ ë¨. íŠ¸ë¦¬ê±° ë©”íŠ¸ë¦­ì—ëŠ” ì˜í–¥ ì—†ìŒ.
- **Code ë„ë©”ì¸ ì•½ì ** (F1=0.16): Alpaca í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ë²¨ë§ì´ ì½”ë“œ ê´€ë ¨ ì¿¼ë¦¬ì—ì„œ ë…¸ì´ì¦ˆê°€ ë§ìŒ.
- **Edge case ì¡´ì¬**: ìœ íš¨í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì–µì œí•˜ê±°ë‚˜ ì² í•™ì  ì§ˆë¬¸ì— toolì„ triggerí•˜ëŠ” ê²½ìš° ë°œìƒ ê°€ëŠ¥. ë°ì´í„° ë¼ë²¨ë§ í’ˆì§ˆ ë¬¸ì œì´ë©°, ASA ìì²´ì˜ í•œê³„ê°€ ì•„ë‹˜.
- **ê°œì„  í­**: F1 0.53â†’0.62ë¡œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ë‚˜, ê°œë³„ caseì—ì„œëŠ” ì˜¤ë¥˜ ê°€ëŠ¥. ë” ì •ë°€í•œ ë¼ë²¨ë§ ë°ì´í„°ë¡œ ê°œì„  ì—¬ì§€ ìˆìŒ.

### ë°ëª¨: Baseline vs ASA

```
[TOOL] "Calculate the average rating for this product"
  Baseline: íŠ¸ë¦¬ê±° ì•ˆ ë¨ âŒ  â†’  ASA: TRIGGERED âœ… (p=0.999, gate=+1)

[NO-TOOL] "Construct an analogy to explain a capacitor"
  Baseline: TRIGGERED âŒ     â†’  ASA: íŠ¸ë¦¬ê±° ì•ˆ ë¨ âœ… (p=0.000, gate=-1)

[TOOL] "Calculate the month number for August 24"
  Baseline: íŠ¸ë¦¬ê±° ì•ˆ ë¨ âŒ  â†’  ASA: TRIGGERED âœ… (p=0.998, gate=+1)

[NO-TOOL] "Provide an analogy to compare a computer to"
  Baseline: TRIGGERED âŒ     â†’  ASA: íŠ¸ë¦¬ê±° ì•ˆ ë¨ âœ… (p=0.021, gate=-1)
```

## ASA ì‘ë™ ì›ë¦¬

```mermaid
graph LR
    A[ì…ë ¥] --> B[ëª¨ë¸ ìˆœì „íŒŒ]
    B --> C{ë ˆì´ì–´ L*=12}
    C --> D[ë¼ìš°í„°: ë„ë©”ì¸ ë¶„ë¥˜]
    D --> E[í”„ë¡œë¸Œ: ë„êµ¬ ì˜ë„ ì ìˆ˜]
    E --> F{3ì§„ ê²Œì´íŠ¸}
    F -->|p â‰¥ Ï„: +1| G[+Î±v ì£¼ì… â†’ ë„êµ¬ í˜¸ì¶œ ì´‰ì§„]
    F -->|p â‰¤ 1-Ï„: -1| H[-Î±v ì£¼ì… â†’ ë„êµ¬ í˜¸ì¶œ ì–µì œ]
    F -->|ê·¸ ì™¸: 0| I[ê°œì… ì—†ìŒ]
    G --> J[ìƒì„± ê³„ì†]
    H --> J
    I --> J
```

**í•µì‹¬ í†µì°°:** LLMì€ ì¢…ì¢… ë„êµ¬ ì‚¬ìš© ì˜ë„ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ í‘œí˜„í•˜ì§€ë§Œ ì‹¤í–‰í•˜ì§€ ëª»í•˜ëŠ” "Lazy Agent" í˜„ìƒì´ ìˆìŠµë‹ˆë‹¤. ASAëŠ” ìˆ¨ê²¨ì§„ ìƒíƒœë¥¼ ë„êµ¬ í˜¸ì¶œ ë°©í–¥ìœ¼ë¡œ ì‚´ì§ ë°€ì–´ì¤Œìœ¼ë¡œì¨ ì´ í‘œí˜„-í–‰ë™ ê°„ê·¹ì„ í•´ì†Œí•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Liquid-ASA/
â”œâ”€â”€ ASA_LFM25_Pipeline.ipynb    # ğŸ““ ë©”ì¸ ë…¸íŠ¸ë¶ (Colab T4)
â”œâ”€â”€ create_notebook.py           # .ipynb ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data/
â”‚   â””â”€â”€ tools.json               # 4ê°œ ë„êµ¬ ì •ì˜ (ìŠ¤í‚¤ë§ˆ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ asa_assets/              # ğŸš€ ë°°í¬ ê°€ëŠ¥ ì—ì…‹ (221KB)
â”‚   â”‚   â”œâ”€â”€ config.json          #    L*=12, Î±=1, Ï„=0.5, Î²=0.0
â”‚   â”‚   â”œâ”€â”€ steering_vectors.npz #    ë„ë©”ì¸+ê¸€ë¡œë²Œ ë²¡í„°
â”‚   â”‚   â”œâ”€â”€ router.pkl           #    ë„ë©”ì¸ ë¶„ë¥˜ê¸°
â”‚   â”‚   â”œâ”€â”€ probes.pkl           #    ë„ë©”ì¸ë³„ intent í”„ë¡œë¸Œ
â”‚   â”‚   â””â”€â”€ scaler.pkl           #    íˆë“  ìŠ¤í…Œì´íŠ¸ ì •ê·œí™”ê¸°
â”‚   â”œâ”€â”€ probe_sweep.png          # ë ˆì´ì–´ AUC ì‹œê°í™”
â”‚   â”œâ”€â”€ hp_sweep.png             # Î±/Ï„/Î² íŠœë‹ ê·¸ë˜í”„
â”‚   â””â”€â”€ baseline_vs_asa.png      # ë¹„êµ ì°¨íŠ¸
â”œâ”€â”€ README.md
â”œâ”€â”€ README_KR.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE
```

## ë¹ ë¥¸ ì‹œì‘

### íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Google Colab)

1. `ASA_LFM25_Pipeline.ipynb`ë¥¼ [Google Colab](https://colab.research.google.com/)ì— ì—…ë¡œë“œ
2. **T4 GPU** ëŸ°íƒ€ì„ ì„ íƒ
3. **ëª¨ë‘ ì‹¤í–‰** â€” ì´ ~30ë¶„

ë…¸íŠ¸ë¶ì´ ìë™ìœ¼ë¡œ Alpaca ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³ , ì—ì…‹ì„ `outputs/`ì— ì €ì¥í•©ë‹ˆë‹¤.

### ì—ì…‹ ì‚¬ìš© (ë¡œì»¬)

íŒŒì´í”„ë¼ì¸ì„ ë‹¤ì‹œ ì‹¤í–‰í•  í•„ìš” ì—†ì´, ì €ì¥ëœ ì—ì…‹ë§Œìœ¼ë¡œ ASAë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import pickle, json, numpy as np, torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# ëª¨ë¸ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(
    "LiquidAI/LFM2.5-1.2B-Instruct",
    dtype=torch.float16, device_map="auto", trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(
    "LiquidAI/LFM2.5-1.2B-Instruct", trust_remote_code=True)

# ASA ì—ì…‹ ë¡œë“œ (ì´ 221KB)
vecs   = np.load("outputs/asa_assets/steering_vectors.npz")
router = pickle.load(open("outputs/asa_assets/router.pkl", "rb"))
probes = pickle.load(open("outputs/asa_assets/probes.pkl", "rb"))
scaler = pickle.load(open("outputs/asa_assets/scaler.pkl", "rb"))
config = json.load(open("outputs/asa_assets/config.json"))

# ASA hook ì •ì˜
_injected = False
def asa_hook(module, inp, out):
    global _injected
    if _injected: return out
    _injected = True
    h = out[0] if isinstance(out, tuple) else out
    hl = h[:, -1, :].detach().cpu().float().numpy()
    hs = scaler.transform(hl)
    dom = config["domains"][router.predict(hs)[0]]
    pt = probes[dom].predict_proba(hs)[0, 1] if dom in probes else 0.5
    gate = 1 if pt >= config["tau"] else (-1 if pt <= 1-config["tau"] else 0)
    if gate == 0: return out
    v = vecs[dom]; v = v / (np.linalg.norm(v) + 1e-8)
    vt = torch.tensor(v, dtype=torch.float16).to(h.device)
    hn = h.clone(); hn[:, -1, :] += gate * config["alpha"] * vt
    rest = out[1:] if isinstance(out, tuple) else None
    return (hn,) + rest if rest else hn

# ì‚¬ìš©ë²•
_injected = False
hook = model.model.layers[config["L_star"]].register_forward_hook(asa_hook)
# ... model.generate() í‰ì†Œì²˜ëŸ¼ ì‚¬ìš© ...
hook.remove()
```

### ëŒ€í™”í˜• ì±„íŒ… (Colab)

ë…¸íŠ¸ë¶ ë§ˆì§€ë§‰ì— ìƒˆ ì…€ ì¶”ê°€:

```python
while True:
    q = input("\nì§ˆë¬¸: ")
    if q.lower() in ("quit", "exit"): break
    msgs = [{"role": "system", "content": SYS_PROMPT},
            {"role": "user", "content": q}]
    bl = generate(msgs)
    _injected = False
    asa_out = generate(msgs, hook_fn=asa_hook, layer=L_STAR)
    print(f"[Baseline] {'ğŸ”§ TOOL' if TOOL_S in bl else 'ğŸ’¬ TEXT'}")
    print(bl[:300])
    print(f"[ASA]      {'ğŸ”§ TOOL' if TOOL_S in asa_out else 'ğŸ’¬ TEXT'}")
    print(asa_out[:300])
```

## LFM2.5 ì ì‘ ì‚¬í•­

| í•­ëª© | ASA ë…¼ë¬¸ (Qwen/LLaMA) | ì´ í”„ë¡œì íŠ¸ (LFM2.5) |
|------|------------------------|----------------------|
| ì•„í‚¤í…ì²˜ | Transformer ì „ìš© | í•˜ì´ë¸Œë¦¬ë“œ LIV conv + GQA |
| íŒŒë¼ë¯¸í„° | 1.5B / 8B | 1.17B |
| ë ˆì´ì–´ | 28â€“32 | 16 (10 LIV + 6 GQA) |
| ë„êµ¬ í† í° | `<functioncall>` | `<\|tool_call_start\|>` / `<\|tool_call_end\|>` |
| ë„êµ¬ í˜•ì‹ | JSON | Bracket í‘œê¸°ë²• `[func(args)]` |
| ìµœì  ë ˆì´ì–´ | L18â€“L21 | **L12** (GQA ë¸”ë¡) |
| ë°ì´í„° ì†ŒìŠ¤ | Alpaca + NQ | Alpaca (ìë™ ë‹¤ìš´ë¡œë“œ) |

## ì¸ìš©

```bibtex
@article{asa2025,
  title={ASA: Training-Free Representation Engineering for Tool-Calling Agents},
  author={...},
  journal={arXiv preprint arXiv:2602.04935},
  year={2025}
}
```

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [Apache License 2.0](LICENSE)ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
