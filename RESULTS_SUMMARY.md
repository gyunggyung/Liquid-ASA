# ASA 전체 실험 결과 종합 분석

> 4개 모델 × 2종 프롬프트, 총 5회 실험의 전체 결과 정리

---

## 1. 실험 개요

### 공통 조건
- **데이터**: [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) 52,002건에서 키워드 필터링
- **도메인**: math, code, search, translation (4개)
- **데이터 분할**: cal 320 / train 320 / valid 320 / test 640 (총 1,600건, tool:non-tool = 1:1)
- **평가 방식**: greedy 디코딩, `<|tool_call_start|>` 또는 `<functioncall>` 트리거 감지
- **ASA 방식**: 최적 레이어(L*)에 스티어링 벡터 주입, 3진 게이트 (gate=+1/0/-1)

### 실험 목록

| # | 모델 | 프롬프트 | 노트북 |
|---|------|---------|--------|
| 1 | LFM2.5-1.2B | Qwen-style | `ASA_LFM25_Pipeline.ipynb` |
| 2 | LFM2.5-1.2B | Liquid 공식 | `ASA_LFM25_LiquidPrompt.ipynb` |
| 3 | Qwen2.5-0.5B | Qwen-style | `ASA_Qwen05B_Reproduction.ipynb` |
| 4 | Qwen2.5-1.5B | Qwen-style | `ASA_Qwen15B_Reproduction.ipynb` |

---

## 2. Probe Sweep (모델이 도구 의도를 얼마나 잘 "인식"하는지)

> Probe AUC = 각 레이어에서 "이 질문에 도구가 필요한지" 분류 정확도 (1.0 = 완벽)

| 모델 | L* (최적 레이어) | AUC | 레이어 총 수 | L* 위치 |
|------|----------------|-----|------------|---------|
| **LFM2.5 Qwen** | **12** | **0.8856** | 16 | 후반부 (GQA 블록) |
| **LFM2.5 Liquid** | **7** | **0.8964** | 16 | 중반부 (LIV 블록) |
| Qwen2.5-0.5B | 9 | 0.8734 | 24 | 중반부 |
| Qwen2.5-1.5B | 12 | 0.8849 | 28 | 중반부 |
| Qwen2.5-1.5B (논문) | 18 | 0.9996 | 28 | 후반부 |

**해석**:
- 우리 실험의 모든 모델이 **0.87~0.90** 대에 수렴 → 차이의 원인은 **데이터** (논문은 비공개 데이터로 0.999 달성)
- LFM2.5 Liquid가 가장 높은 AUC (0.8964) → **모델 내부에서 도구 의도를 가장 잘 인식**
- LFM2.5 Liquid의 L*가 7로 더 앞쪽 → 짧은 프롬프트가 **초기 처리를 변화**시킴

---

## 3. 스티어링 벡터 (도메인별 "도구 사용 방향")

> cos(v_d, v_global) = 각 도메인의 스티어링 벡터가 전체 방향과 얼마나 일치하는지

| 도메인 | LFM2.5 Qwen | LFM2.5 Liquid | Qwen 0.5B | Qwen 1.5B |
|--------|-------------|---------------|-----------|-----------|
| math | 0.7263 | 0.7037 | 0.7097 | 0.7304 |
| code | 0.3282 | 0.4614 | 0.3755 | 0.3674 |
| search | 0.7119 | 0.7074 | 0.7326 | 0.7400 |
| translation | 0.6002 | 0.6359 | 0.6774 | 0.4870 |

**해석**:
- **Code는 항상 가장 독특** (cos < 0.47) → 다른 도메인과 다른 방향의 도구 사용 패턴
- Math와 Search는 글로벌 방향과 잘 정렬 (cos > 0.70) → 대표적인 "도구 필요" 패턴
- Liquid 포맷에서 Code의 정렬이 소폭 상승 (0.33→0.46) → 프롬프트 변경이 도메인별 구조에도 영향

---

## 4. 라우터 & 프로브 (ASA 분류기 성능)

> 라우터 = "어떤 도메인인지" 분류, 프로브 = "도구가 필요한지" 이진 분류

### 라우터 검증 정확도

| 모델 | 학습 | 검증 |
|------|------|------|
| LFM2.5 Qwen | 1.0000 | 0.7469 |
| LFM2.5 Liquid | 1.0000 | **0.7656** |
| Qwen 0.5B | 1.0000 | 0.7219 |
| Qwen 1.5B | 1.0000 | 0.7500 |

### 프로브 검증 정확도 (도메인별)

| 도메인 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B |
|--------|----------|------------|-----------|-----------|
| math | 0.8875 | **0.9000** | 0.9000 | 0.8875 |
| code | 0.7000 | 0.6875 | 0.6875 | 0.6875 |
| search | 0.9250 | **0.9500** | 0.9375 | 0.9125 |
| translation | 1.0000 | 1.0000 | 1.0000 | 1.0000 |

**해석**:
- 모든 모델에서 **학습=100%, 검증=72~77%** (일정한 과적합)
- **Code 프로브가 항상 최약** (~69%) → Alpaca의 코드 라벨 노이즈 때문
- Translation 프로브는 **항상 100%** → 번역 쿼리가 가장 구분하기 쉬움
- LFM Liquid가 대부분의 프로브에서 미세하게 나음

---

## 5. 하이퍼파라미터 튜닝

> α = 스티어링 강도, τ = 게이트 임계값, β = 글로벌/도메인 혼합 비율

| 파라미터 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B | 논문 (1.5B) |
|----------|----------|------------|-----------|-----------|-------------|
| **α** | 1 | 1 | 1 | 1 | 4 |
| **τ** | 0.50 | 0.50 | 0.50 | 0.50 | 0.60 |
| **β** | 0.0 | 0.0 | 0.0 | 0.0 | — |

**해석**:
- 모든 실험에서 α=1, τ=0.50, β=0.0으로 동일하게 선택됨
- 논문은 α=4, τ=0.60 → 더 강한 스티어링, 더 보수적인 게이트
- **τ=0.50은 매우 공격적** → 확률 50% 이상이면 바로 gate=+1 또는 -1 발동
- 이것이 Liquid 포맷에서 **과잉 억제**의 원인일 가능성 높음

---

## 6. ⭐ 핵심: TEST 결과 (640 샘플, Generation 레벨)

> 실제로 모델이 도구 호출 토큰을 생성했는지 평가

### Baseline (ASA 없음)

| 메트릭 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B |
|--------|----------|------------|-----------|-----------|
| **Precision** | 0.4959 | 0.4927 | 0.5821 | **0.7857** |
| **Recall** | 0.5656 | **0.6312** | 0.1219 | 0.4125 |
| **F1** | 0.5285 | **0.5534** | 0.2016 | **0.5410** |
| **FPR** | 0.5750 | 0.6500 | **0.0875** | **0.1125** |
| **Accuracy** | 0.4953 | 0.4906 | 0.5172 | **0.6500** |

**해석**:
- **LFM2.5**: 두 프롬프트 모두 FPR이 58~65% → **"항상 도구를 꺼내려 하는" 모델 특성**
- **Qwen 0.5B**: FPR은 낮지만 (9%) Recall이 극도로 낮음 (12%) → **도구를 거의 안 꺼냄** (능력 부족)
- **Qwen 1.5B**: 가장 균형 잡힌 baseline (F1=0.54, FPR=0.11) → **이미 잘 작동**

### ASA 적용

| 메트릭 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B |
|--------|----------|------------|-----------|-----------|
| **Precision** | **0.7591** | 0.6476 | 0.6176 | 0.7857 |
| **Recall** | **0.5219** | 0.2125 | 0.1313 | 0.4125 |
| **F1** | **0.6185** | 0.3200 | 0.2165 | 0.5410 |
| **FPR** | 0.1656 | **0.1156** | 0.0813 | 0.1125 |
| **Accuracy** | **0.6781** | 0.5484 | 0.5250 | 0.6500 |

**해석**:
- **LFM Qwen + ASA가 현재 최고 조합**: F1=0.62, FPR=0.17 (최고의 균형)
- **LFM Liquid + ASA**: FPR 최저치 (0.116)지만 Recall 폭락 (0.21) → 과잉 억제
- **Qwen 0.5B**: ASA 효과 미미 (+7%) → 모델 능력 한계
- **Qwen 1.5B**: ASA 효과 없음 (0%) → 이미 잘 작동해서 개선 여지 없음

### ASA 전후 개선율 (상대)

| 메트릭 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B |
|--------|----------|------------|-----------|-----------|
| **ΔF1** | **+17%** | -42% | +7% | 0% |
| **ΔFPR** | **-71%** | **-82%** | -7% | 0% |
| **ΔPrecision** | **+53%** | +31% | +6% | 0% |
| **ΔRecall** | -8% | **-66%** | +8% | 0% |

---

## 7. 도메인별 ASA 결과

### LFM2.5 Qwen-style (최고 F1)

| 도메인 | Precision | Recall | F1 | FPR |
|--------|-----------|--------|-----|-----|
| **번역** | **1.0000** | **0.8625** | **0.9262** | **0.0000** |
| 수학 | 0.7568 | 0.7000 | 0.7273 | 0.2250 |
| 검색 | 0.7857 | 0.4125 | 0.5410 | 0.1125 |
| 코드 | 0.2571 | 0.1125 | 0.1565 | 0.3250 |

### LFM2.5 Liquid (최저 FPR)

| 도메인 | Precision | Recall | F1 | FPR |
|--------|-----------|--------|-----|-----|
| **번역** | **0.8571** | 0.0750 | 0.1379 | **0.0125** |
| 수학 | 0.3636 | 0.1500 | 0.2124 | 0.2625 |
| 코드 | 0.5833 | 0.1750 | 0.2692 | 0.1250 |
| 검색 | 0.7500 | 0.3000 | 0.4286 | 0.1000 |

**해석**:
- Qwen-style: **번역 도메인이 압도적** (F1=0.93) → ASA가 번역 쿼리에 가장 정확하게 작동
- Liquid: 모든 도메인에서 **Recall이 폭락** (0.07~0.30) → 과잉 억제가 전 도메인에 영향
- Liquid에서 코드 FPR이 0.325→0.125로 개선된 건 긍정적

---

## 8. Ablation 연구 (Probe 레벨)

> Probe 레벨 = 모델이 "생각"한 것을 기반으로 평가 (실제 생성 X)

| 변형 | LFM Qwen F1 | LFM Liquid F1 | Qwen 0.5B F1 | Qwen 1.5B F1 |
|------|-------------|---------------|--------------|--------------|
| **Full ASA** | 0.8054 | **0.8092** | 0.7870 | 0.7969 |
| No Gate | 0.6667 | 0.6667 | 0.6667 | 0.6667 |
| Global Only | 0.8054 | 0.8092 | 0.7870 | 0.7969 |
| Domain Only | 0.8054 | 0.8092 | 0.7870 | 0.7969 |

| 변형 | LFM Qwen FPR | LFM Liquid FPR | Qwen 0.5B FPR | Qwen 1.5B FPR |
|------|--------------|----------------|---------------|----------------|
| **Full ASA** | 0.2375 | **0.2094** | 0.2281 | 0.2219 |
| No Gate | 1.0000 | 1.0000 | 1.0000 | 1.0000 |
| Global Only | 0.2375 | 0.2094 | 0.2281 | 0.2219 |
| Domain Only | 0.2375 | 0.2094 | 0.2281 | 0.2219 |

**핵심 발견**:
- **Gate가 없으면 FPR=1.0** (모든 것에 도구 호출) → 게이트가 핵심 안전장치
- **Global Only = Domain Only = Full** → β=0으로 선택되어 동일 결과
- **LFM Liquid가 Probe 레벨에서 최고** → 내부 표현이 가장 깨끗

---

## 9. Success Precision (도구 호출 품질)

> 모델이 도구를 트리거한 경우, 생성된 JSON이 유효한지

| 메트릭 | LFM Qwen | LFM Liquid | Qwen 0.5B | Qwen 1.5B | 논문 1.5B |
|--------|----------|------------|-----------|-----------|-----------|
| **JSON Valid** | 0.0000 | 0.0000 | 0.0441 | 0.3333 | **0.8800** |
| **Schema OK** | 0.0000 | 0.0000 | 0.0147 | 0.3214 | **0.6923** |
| **Args OK** | 0.0000 | 0.0000 | 0.0441 | 0.0655 | **0.8700** |

**해석**:
- **LFM2.5**: 두 포맷 모두 JSON 생성 불가 → bracket 형식 `[func(args)]`으로 출력하기 때문
- **Qwen 1.5B**: 33% 확률로 유효 JSON → 논문의 88%에 크게 미달
- **이건 트리거 메트릭과 무관** → 도구를 "꺼내는 타이밍"과 "꺼낸 도구의 품질"은 별개

---

## 10. 종합 순위

### 실용 관점 (Generation 레벨)

| 순위 | 조합 | F1 | FPR | 추천 |
|------|------|-----|-----|------|
| 🥇 | **LFM2.5 Qwen + ASA** | **0.6185** | 0.1656 | ✅ **현재 최선** |
| 🥈 | LFM2.5 Liquid Baseline | 0.5534 | 0.6500 | ⚠️ FPR 너무 높음 |
| 🥉 | Qwen 1.5B Baseline/ASA | 0.5410 | 0.1125 | ⚠️ ASA 효과 없음 |
| 4 | LFM2.5 Qwen Baseline | 0.5285 | 0.5750 | ❌ FPR 너무 높음 |
| 5 | LFM2.5 Liquid + ASA | 0.3200 | **0.1156** | ❌ Recall 폭락 |
| 6 | Qwen 0.5B + ASA | 0.2165 | 0.0813 | ❌ 모델 능력 부족 |

### 내부 표현 관점 (Probe 레벨)

| 순위 | 조합 | Probe F1 | Probe AUC | 의미 |
|------|------|----------|-----------|------|
| 🥇 | **LFM2.5 Liquid** | **0.8092** | **0.8964** | 가장 깨끗한 내부 표현 |
| 🥈 | LFM2.5 Qwen | 0.8054 | 0.8856 | |
| 🥉 | Qwen 1.5B | 0.7969 | 0.8849 | |
| 4 | Qwen 0.5B | 0.7870 | 0.8734 | |

---

## 11. 핵심 발견 요약

### 발견 1: 모델마다 문제가 다르다

| 모델 | 문제 유형 | 비유 |
|------|----------|------|
| **LFM2.5** | 과다 트리거 (FPR 58~65%) | "맨날 칼을 꺼내는 요리사" |
| **Qwen 0.5B** | 과소 트리거 (Recall 12%) | "칼이 있는데 안 쓰는 요리사" |
| **Qwen 1.5B** | 문제 없음 (이미 양호) | "적당히 잘 하는 요리사" |

### 발견 2: ASA는 "과다 트리거" 모델에서만 극적 효과

| 모델 | ASA ΔFPR | ASA ΔF1 | 효과 |
|------|----------|---------|------|
| **LFM2.5 Qwen** | **-71%** | **+17%** | ⭐ 극적 |
| **LFM2.5 Liquid** | **-82%** | -42% | ⚠️ FPR↓ but Recall↓↓ |
| Qwen 0.5B | -7% | +7% | 미미 |
| Qwen 1.5B | 0% | 0% | 없음 |

### 발견 3: 프롬프트는 행동이 아닌 내부 표현에 영향

| | Qwen-style | Liquid 공식 |
|--|-----------|-------------|
| 모델 내부 (Probe AUC) | 0.886 | **0.896** (더 나음) |
| 모델 행동 (Baseline FPR) | 0.575 | 0.650 (더 나쁨) |
| **결론** | 생각 ≠ 행동 | **표현-행동 간극** |

### 발견 4: L* 이동은 프롬프트가 정보 처리를 바꾸는 증거

| 프롬프트 | L* | 블록 타입 | 의미 |
|---------|-----|----------|------|
| Qwen-style (긴 프롬프트) | 12 | GQA (어텐션) | 후반부에서 의도 형성 |
| Liquid (짧은 프롬프트) | 7 | LIV (컨볼루션) | 초기에 의도 형성 |

---

## 12. 다음 실험: ASA 억제 완화 (Liquid + τ/α 튜닝)

### 문제 정의
Liquid 포맷에서 ASA의 FPR 감소는 최고 (-82%)이지만 Recall이 폭락 (-66%).
**τ를 높이면 억제를 줄여서 Recall을 살릴 수 있다.**

### 현재 설정과 제안

| 파라미터 | 현재값 | 의미 | 제안 |
|----------|-------|------|------|
| **τ** | 0.50 | 확률 50% 이상이면 바로 gate 발동 | **0.65~0.80** → 더 확실할 때만 발동 |
| **α** | 1 | 스티어링 강도 최소 | **2~5** → 도구 방향으로 더 세게 밀기 |

### 예상 효과

```
현재 (τ=0.50):
  probe가 "도구 필요" 51%라고 판단 → gate=+1 발동 (너무 쉽게 발동)
  probe가 "도구 불필요" 51%라고 판단 → gate=-1 발동 (너무 쉽게 억제)

제안 (τ=0.70):
  probe가 "도구 필요" 70% 이상일 때만 → gate=+1 (확실할 때만 촉진)
  probe가 "도구 불필요" 70% 이상일 때만 → gate=-1 (확실할 때만 억제)
  그 사이 (30~70%) → gate=0 (모델 자율에 맡김)
```

### 실험 매트릭스 (제안)

| 실험 | τ | α | 예상 효과 |
|------|---|---|----------|
| A | 0.60 | 1 | 약간의 억제 완화 |
| B | 0.65 | 1 | 중간 완화 |
| C | 0.70 | 1 | 상당한 완화 |
| D | 0.70 | 3 | 완화 + 촉진 강화 |
| E | 0.80 | 5 | 최대 완화 + 강한 촉진 |
